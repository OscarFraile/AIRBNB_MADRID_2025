{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e4c4ff4",
   "metadata": {},
   "source": [
    "# CODIGO DE RE-ENTRENAMIENTO SOFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Posibles paquetes necesarios para el desarrollo del proyecto. No harán falta todos siempre. Seleccionar los necesarios\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import cloudpickle #Mismas funciones de pickle de guardar modelos + funciones de guardado de las funciones específicasimport seaborn as sns\n",
    "import sqlalchemy as sa\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy = True\n",
    "\n",
    "#Formato sin notación científica\n",
    "pd.options.display.float_format = '{:15.2f}'.format \n",
    "\n",
    "#Automcompletar rápido\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "#Desactivar los warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Representación visual de un pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display = 'diagram') #diagram/text \n",
    "\n",
    "#Transformación de variables\n",
    "from janitor import clean_names\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Modelos ML: CLASIFICACIÓN\n",
    "from xgboost import XGBClassifier\n",
    "#Métrica de error: Habrá que incluir la que necesitemos\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# PRECIO_M2 IDEALISTA\n",
    "#Ruta del proyecto\n",
    "ruta_proyecto = 'C:/Users/Oscar/OneDrive - FM4/Escritorio/Python Data Mastery/EstructuraDirectorio/03_MACHINE_LEARNING/08_CASOS/007_AIRBNB'\n",
    "\n",
    "#Nombre del fichero de datos\n",
    "nombre_fichero_datos = 'precios_idealista_Dic24.csv'\n",
    "\n",
    "#Cargar los datos\n",
    "ruta_completa = ruta_proyecto + '/02_Datos/01_Originales/' + nombre_fichero_datos\n",
    "precio_m2 = pd.read_csv(ruta_completa)\n",
    "\n",
    "def modificaciones_idealista(precio_m2):\n",
    "    precio_m2 = precio_m2.loc[1:,['table__cell 2','icon-elbow']] \\\n",
    "    .rename(columns = {'table__cell 2':'precio_m2','icon-elbow':'neighbourhood_group'})\n",
    "    \n",
    "    precio_m2['precio_m2'] = precio_m2['precio_m2'].str.replace(' €/m2','').str.replace('.','').astype('int')\n",
    "    \n",
    "    return(precio_m2)\n",
    "precio_m2 = modificaciones_idealista(precio_m2)\n",
    "precio_m2\n",
    "\n",
    "\n",
    "# LISTINGS AIRBNB\n",
    "#Ruta del proyecto\n",
    "ruta_proyecto = 'C:/Users/Oscar/OneDrive - FM4/Escritorio/Python Data Mastery/EstructuraDirectorio/03_MACHINE_LEARNING/08_CASOS/007_AIRBNB'\n",
    "\n",
    "con = sa.create_engine('sqlite:///C:/Users/Oscar/OneDrive - FM4/Escritorio/Python Data Mastery/EstructuraDirectorio/03_MACHINE_LEARNING/08_CASOS/007_AIRBNB/02_Datos/01_Originales/airbnb2025.db')\n",
    "\n",
    "#Nombre del fichero de datos\n",
    "nombre_fichero_datos = 'airbnb2025.db'\n",
    "\n",
    "#Cargar los datos\n",
    "ruta_completa = ruta_proyecto + '/02_Datos/01_Originales/' + nombre_fichero_datos\n",
    "listings = pd.read_sql('listings', con).drop(columns='index')#.set_index('id')\n",
    "\n",
    "\n",
    "\n",
    "# LISTINGS_DET AIRBNB\n",
    "#Ruta del proyecto\n",
    "ruta_proyecto = 'C:/Users/Oscar/OneDrive - FM4/Escritorio/Python Data Mastery/EstructuraDirectorio/03_MACHINE_LEARNING/08_CASOS/007_AIRBNB'\n",
    "\n",
    "con = sa.create_engine('sqlite:///C:/Users/Oscar/OneDrive - FM4/Escritorio/Python Data Mastery/EstructuraDirectorio/03_MACHINE_LEARNING/08_CASOS/007_AIRBNB/02_Datos/01_Originales/airbnb2025.db')\n",
    "\n",
    "#Nombre del fichero de datos\n",
    "nombre_fichero_datos = 'airbnb2025.db'\n",
    "\n",
    "#Cargar los datos\n",
    "ruta_completa = ruta_proyecto + '/02_Datos/01_Originales/' + nombre_fichero_datos\n",
    "listings_det = pd.read_sql('listings_det', con).drop(columns='index')#.set_index('id')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "def preparacion_df(listings_det, listings, precio_m2):\n",
    "    \n",
    "    a_eliminar = [\n",
    "     'listing_url',\n",
    "     'scrape_id',\n",
    "     'last_scraped',\n",
    "     'source',\n",
    "     'description',\n",
    "     'neighborhood_overview',\n",
    "     'picture_url',\n",
    "     'host_url',\n",
    "     'host_name',\n",
    "     'host_location',\n",
    "     'host_about',\n",
    "     'host_picture_url',\n",
    "     'host_neighbourhood',\n",
    "     'neighbourhood',\n",
    "     'neighbourhood_group_cleansed',\n",
    "     'minimum_minimum_nights',\n",
    "     'maximum_minimum_nights',\n",
    "     'minimum_maximum_nights',\n",
    "     'maximum_maximum_nights',\n",
    "     'minimum_nights_avg_ntm',\n",
    "     'maximum_nights_avg_ntm',\n",
    "     'calendar_updated',\n",
    "     'calendar_last_scraped',\n",
    "     'host_thumbnail_url']\n",
    "    listings_det = listings_det.drop(columns = a_eliminar)    \n",
    "    \n",
    "    # 1. Normalización del nombre de barrios\n",
    "    def join_listings(listings_det, listings):\n",
    "        listings['neighbourhood_group'] = listings['neighbourhood_group'].replace({\n",
    "            'Fuencarral - El Pardo': 'Fuencarral',\n",
    "            'Moncloa - Aravaca': 'Moncloa',\n",
    "            'San Blas - Canillejas': 'San Blas'\n",
    "        })\n",
    "        listings_det = pd.merge(left=listings_det, right=listings[['id', 'neighbourhood_group']], how='left', on='id')\n",
    "        return listings_det\n",
    "\n",
    "    listings_det = join_listings(listings_det, listings)\n",
    "\n",
    "    # 2. Join con precios por metro cuadrado\n",
    "    def join_df(listings_det, precio_m2):\n",
    "        df = pd.merge(left=listings_det, right=precio_m2, how='left', on='neighbourhood_group')\n",
    "        return df\n",
    "    df = join_df(listings_det, precio_m2)\n",
    "    return df\n",
    "\n",
    "df = preparacion_df(listings_det, listings, precio_m2)\n",
    "\n",
    "\n",
    "#Traemos las variables que corresponden. Todas las funciones que usamos anteriormente en los notebooks están aquí \n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def calidad_datos(df):\n",
    "    \n",
    "    # Limpiamos los nombres de las variables por si hubiera algun carácter extraño\n",
    "    df = clean_names(df)\n",
    "    \n",
    "    # Borramos duplicados\n",
    "    #df.drop_duplicates(inplace = True)\n",
    "    \n",
    "    # Creamos una tabla temporal con una copia de df para trabajar sobre ella\n",
    "    temp = df.copy()\n",
    "    \n",
    "    #PRICE\n",
    "    def price(temp):\n",
    "        \n",
    "        # Asegurarse de que 'price' es numérico\n",
    "        temp['price'] = temp['price'].replace(r'[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "        # 1. Promedio por 'neighbourhood_cleansed' y 'accommodates'\n",
    "        grouped_price = temp.groupby(['neighbourhood_cleansed', 'accommodates'])['price'].mean()\n",
    "\n",
    "        # 2. Promedio por 'accommodates'\n",
    "        grouped_accommodates_price = temp.groupby('accommodates')['price'].mean()\n",
    "\n",
    "        # 3. Promedio general\n",
    "        global_price_mean = temp['price'].mean()\n",
    "\n",
    "        # Función de imputación\n",
    "        def imputar_precio(registro):\n",
    "            if pd.isna(registro['price']):\n",
    "                val = grouped_price.get((registro['neighbourhood_cleansed'], registro['accommodates']), np.nan)\n",
    "                if pd.isna(val):\n",
    "                    val = grouped_accommodates_price.get(registro['accommodates'], np.nan)\n",
    "                if pd.isna(val):\n",
    "                    val = global_price_mean\n",
    "                return round(val) if pd.notna(val) else np.nan\n",
    "            else:\n",
    "                return registro['price']\n",
    "\n",
    "        # Aplicar la imputación\n",
    "        temp['price'] = temp.apply(imputar_precio, axis=1)   \n",
    "        return temp        \n",
    "    temp = price(temp)\n",
    "    \n",
    "    # Seleccionar solamente los inmuebles con un precio superior a 20€ por noche\n",
    "    temp = temp.loc[temp['price']>=20]\n",
    "    \n",
    "    #BEDS\n",
    "    def imputar_beds(registro):\n",
    "        if pd.notna(registro['beds']):\n",
    "            return registro['beds']\n",
    "        if registro['accommodates'] <= 2:\n",
    "            return 1\n",
    "        elif registro['accommodates'] <= 4:\n",
    "            return 2\n",
    "        elif registro['accommodates'] <= 6:\n",
    "            return 3\n",
    "        else:\n",
    "            return 4\n",
    "        \n",
    "    temp['beds'] = temp.apply(imputar_beds, axis=1).astype(float) \n",
    "    \n",
    "    #BEDROOMS\n",
    "    def imputar_bedrooms(registro):\n",
    "        if pd.notna(registro['bedrooms']):\n",
    "            return registro['bedrooms']\n",
    "        if registro['beds'] <= 2:\n",
    "            return 1\n",
    "        elif registro['beds'] <= 4:\n",
    "            return 2\n",
    "        elif registro['beds'] <= 6:\n",
    "            return 3\n",
    "        else:\n",
    "            return 4\n",
    "        \n",
    "    temp['bedrooms'] = temp.apply(imputar_bedrooms, axis=1).astype(float) \n",
    "    \n",
    "    #BATHROOMS\n",
    "    \n",
    "    #1. bathrooms_text None --> 0\n",
    "    #2. bathrooms_text quitamos el texto detras del numero\n",
    "    #3. bathrooms_text sustituimos los NaN generados por 0.5\n",
    "    #4. bathrooms sustituimos los NaN por los valores de bathrooms_text del mismo registro\n",
    "    #5. Eliminamos bathrooms_text porque ya tenemos completa la variable bathrooms\n",
    "      \n",
    "    def bathrooms(temp):\n",
    "        temp['bathrooms_text'] = temp['bathrooms_text']\\\n",
    "            .replace(np.nan, '0')\\\n",
    "            .replace(r'[^\\d.]', '', regex=True)\\\n",
    "            .replace('', '0.5').astype('float64')\n",
    "        temp['bathrooms'] = np.where(temp.bathrooms.isna(), temp.bathrooms_text, temp.bathrooms)\n",
    "        #temp.drop(columns='bathrooms_text', inplace=True)\n",
    "        return temp\n",
    "    temp = bathrooms(temp)      \n",
    "    \n",
    "    #REVIEWS\n",
    "    var_reviews = ['review_scores_rating',\n",
    "                     'review_scores_accuracy',\n",
    "                     'review_scores_cleanliness',\n",
    "                     'review_scores_checkin',\n",
    "                     'review_scores_communication',\n",
    "                     'review_scores_location',\n",
    "                     'review_scores_value']\n",
    "    valor = 0\n",
    "    def reviews(temp):\n",
    "        for col in var_reviews:\n",
    "            temp[col] = np.where(\n",
    "                temp[col].isna(), \n",
    "                temp['review_scores_rating'], \n",
    "                temp[col])\n",
    "        temp[var_reviews] = temp[var_reviews].fillna(valor)\n",
    "        return temp\n",
    "    temp = reviews(temp)\n",
    "    \n",
    "    #HOST RESPONSE TIME    \n",
    "    valor = 'no response'\n",
    "    temp['host_response_time'] = temp['host_response_time'].fillna(valor)\n",
    "    \n",
    "    #HOST RESPONSE RATE\n",
    "    temp['host_response_rate'] = temp['host_response_rate'].replace('%','', regex=True)\n",
    "    temp['host_response_rate'] = np.where(temp['host_response_rate'].isna(), 0,\\\n",
    "                                          temp['host_response_rate']).astype('float')\n",
    "    \n",
    "    #LICENSE\n",
    "    temp['license'] = np.where(temp['license'].notna(), 'yes', 'no')    \n",
    "    \n",
    "    #HAS AVAILABILITY\n",
    "    temp['has_availability'] = np.where(temp['has_availability'].notna(), 'yes', 'no')\n",
    "\n",
    "    #HOST IS SUPERHOST\n",
    "    def host_is_superhost(temp):\n",
    "        # Función para imputar\n",
    "        def imputar_is_superhost(registro):\n",
    "            if pd.isna(registro['host_is_superhost']):\n",
    "                scores = [\n",
    "                    registro['review_scores_cleanliness'],\n",
    "                    registro['review_scores_accuracy'],\n",
    "                    registro['review_scores_rating'],\n",
    "                    registro['review_scores_communication'],\n",
    "                    registro['review_scores_checkin'],\n",
    "                    registro['review_scores_location'],\n",
    "                    registro['review_scores_value']\n",
    "                ]\n",
    "                # Verificar que todos los puntajes no son nulos y mayores a 4.5\n",
    "                if all(pd.notna(score) and score > 4.5 for score in scores):\n",
    "                    return 't'\n",
    "                else:\n",
    "                    return 'f'\n",
    "            return registro['host_is_superhost']\n",
    "\n",
    "        # Aplicar la imputación\n",
    "        temp['host_is_superhost'] = temp.apply(imputar_is_superhost, axis=1)\n",
    "\n",
    "        return temp\n",
    "    temp = host_is_superhost(temp)\n",
    "    \n",
    "    #HOST VERIFICATIONS\n",
    "    temp['host_verifications'] = np.where(temp['host_verifications']=='[]', \"['No']\", temp['host_verifications'])\n",
    "    temp['host_verifications'] = np.where(temp.host_verifications == \"['email', 'work_email']\", \n",
    "                                          \"['email']\", \n",
    "                                          temp.host_verifications)\n",
    "    \n",
    "    #MINIMUM NIGHTS / MAXIMUM NIGHTS\n",
    "    def atipicos_desv_tip(variable, num_desv_tip = 4):\n",
    "        #sacamos los nulos por ahora\n",
    "        variable = variable.dropna()\n",
    "        #calculamos los límites\n",
    "        media = np.mean(variable)\n",
    "        sd = np.std(variable)\n",
    "        umbral = sd * num_desv_tip\n",
    "        lim_inf = media - umbral\n",
    "        lim_sup = media + umbral\n",
    "        #encontramos los índices de los que están fuera de los límites\n",
    "        indices = [indice for indice,valor in variable.items() if valor < lim_inf or valor > lim_sup]\n",
    "        return(indices)\n",
    "    var_atipicos_desv_tip = ['minimum_nights', 'maximum_nights']\n",
    " \n",
    "    # ELIMINAMOS LOS HOTELES PORQUE NO SON NUESTRO OBJETIVO\n",
    "    temp = temp.loc[~((temp.property_type.str.contains('hotel', case=False, na=False))|\n",
    "                      (temp.property_type.str.contains('hostel', case=False, na=False))|\n",
    "                      (temp.room_type.str.contains('hotel', case=False, na=False)))]\n",
    "    \n",
    "    #Agrupar categorias raras\n",
    "    def agrupar_cat_raras(variable, criterio = 0.02):\n",
    "        #Calcula las frecuencias\n",
    "        frecuencias = variable.value_counts(normalize=True)\n",
    "        #Identifica las que están por debajo del criterio\n",
    "        temp = [cada for cada in frecuencias.loc[frecuencias < criterio].index.values]\n",
    "        #Las recodifica en 'OTROS'\n",
    "        temp2 = np.where(variable.isin(temp),'OTROS',variable)\n",
    "        #Devuelve el resultado\n",
    "        return(temp2)\n",
    "    var_agrupar_cat_raras = ['property_type']\n",
    "    for variable in var_agrupar_cat_raras:\n",
    "        temp[variable] = agrupar_cat_raras(temp[variable],criterio = 0.02)    \n",
    "    \n",
    "    # Eliminamos todas los registros que no tengan 50 variables sin nulos después de todo el proceso de calidad de datos \n",
    "    criterio = 50 #Elimina todos los registros que no tengan el número de variables del criterio sin nulos\n",
    "    temp.dropna(thresh=criterio, inplace=True)\n",
    "    temp.isna().sum().sort_values(ascending=True)\n",
    "    \n",
    "    return temp\n",
    "df = calidad_datos(df)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "def gestion_variables(df):\n",
    "    # 1. Estimación de m2 por número de dormitorios\n",
    "    condiciones = [df.bedrooms == 0,\n",
    "                   df.bedrooms == 1,\n",
    "                   df.bedrooms == 2,\n",
    "                   df.bedrooms == 3,\n",
    "                   df.bedrooms == 4,\n",
    "                   df.bedrooms > 4]\n",
    "    resultados = [40, 50, 70, 90, 120, 150]\n",
    "    df['m2'] = np.select(condiciones, resultados, default=-999)\n",
    "\n",
    "    # 2. Estimación de precio de compra\n",
    "    df['precio_compra'] = df['m2'] * df['precio_m2'] * 0.8\n",
    "\n",
    "    # 3. Cálculo de disponibilidad promedio por tipo de habitación\n",
    "    dispo_private = df[df['room_type'] == 'Private room']['availability_365'].mean() / 365\n",
    "    dispo_shared = df[df['room_type'] == 'Shared room']['availability_365'].mean() / 365\n",
    "\n",
    "    # 4. Cálculo del precio total estimado\n",
    "    def crear_precio_total(registro):\n",
    "        try:\n",
    "            price = float(registro.price)\n",
    "            beds = float(registro.beds)\n",
    "        except (ValueError, TypeError):\n",
    "            return np.nan\n",
    "\n",
    "        room = registro.room_type\n",
    "        if pd.isna(price) or pd.isna(beds) or pd.isna(room):\n",
    "            return np.nan\n",
    "\n",
    "        if beds > 1 and room == 'Private room':\n",
    "            return price * beds * (1 - dispo_private)\n",
    "        elif beds > 1 and room == 'Shared room':\n",
    "            return price * beds * (1 - dispo_shared)\n",
    "        else:\n",
    "            return price\n",
    "\n",
    "    df['precio_total'] = df.apply(crear_precio_total, axis=1).round(2)\n",
    "    \n",
    "    # 5. Determinar la ocupación del inmueble\n",
    "    df['ocupacion'] = ((365 - df.availability_365) / 365 * 100).astype('int')\n",
    "    \n",
    "    # 6. Creación de las distancias a un pdi\n",
    "    from math import radians, cos, sin, asin, sqrt\n",
    "    def haversine(lat1, lon1, lat2, lon2):\n",
    "\n",
    "          R = 6372.8 #En km, si usas millas tienes que cambiarlo por 3959.87433\n",
    "\n",
    "          dLat = radians(lat2 - lat1)\n",
    "          dLon = radians(lon2 - lon1)\n",
    "          lat1 = radians(lat1)\n",
    "          lat2 = radians(lat2)\n",
    "\n",
    "          a = sin(dLat/2)**2 + cos(lat1)*cos(lat2)*sin(dLon/2)**2\n",
    "          c = 2*asin(sqrt(a))\n",
    "\n",
    "          return R * c\n",
    "    #Las coordenadas de la Puerta del Sol serán lat1 y lon1\n",
    "    lat1 = 40.4167278\n",
    "    lon1 = -3.7033387\n",
    "\n",
    "    df['pdi_sol'] = df.apply(lambda registro: haversine(lat1,lon1,registro['latitude'],registro['longitude']),axis=1)\n",
    "\n",
    "    # 7. Determinar si el piso es rentable\n",
    "    df['pisos_rentables'] = np.where(df['precio_compra'] / 10 > df['precio_total'] * df['ocupacion'] * 10, 0, 1)\n",
    "    \n",
    "    def variables_texto(df):\n",
    "        if os.path.exists(\"count_vectorizer.pkl\"):\n",
    "            with open(\"count_vectorizer.pkl\", \"rb\") as f:\n",
    "                cv = pickle.load(f)\n",
    "        else:\n",
    "            cv = CountVectorizer()\n",
    "            cv.fit(df[\"amenities\"].astype(str))\n",
    "            with open(\"count_vectorizer.pkl\", \"wb\") as f:\n",
    "                pickle.dump(cv, f)\n",
    "        #Aplicamos\n",
    "        caracteristicas = cv.transform(df[\"amenities\"].astype(str))\n",
    "        \n",
    "        #Definimos un dataframe con los términos encontrados transformados a variables que mapean las columnas donde se encuentran\n",
    "        terminos = pd.DataFrame(caracteristicas.toarray(), columns=cv.get_feature_names_out(), index=df.index)\n",
    "        \n",
    "        #Concatenar al DataFrame original        \n",
    "        df = pd.concat([df, terminos], axis=1)    \n",
    "        return df\n",
    "    df = variables_texto(df)\n",
    "    \n",
    "    return df\n",
    "df = gestion_variables(df)\n",
    "\n",
    "id_df = df['id'].copy()\n",
    "\n",
    "\n",
    "variables_finales = [\n",
    "'accommodates',\n",
    "'availability_30',\n",
    "'availability_365',\n",
    "'availability_90',\n",
    "'bedrooms',\n",
    "'bed',\n",
    "'calculated_host_listings_count',\n",
    "'has_availability',\n",
    "'host_response_rate',\n",
    "'host_response_time',\n",
    "'instant_bookable',\n",
    "'maximum_nights',\n",
    "'neighbourhood_group',\n",
    "'price',\n",
    "'property_type',\n",
    "'room_type',\n",
    "'license',\n",
    "'bathrooms',\n",
    "'air',\n",
    "'allowed',\n",
    "'cleaning',\n",
    "'hot water iron',\n",
    "'iron',\n",
    "'microwave',\n",
    "'parking',\n",
    "'refrigerator',\n",
    "'shampoo',\n",
    "'tv washer',\n",
    "'wifi kitchen',\n",
    "'neighbourhood_cleansed',\n",
    "'and silverware',\n",
    "'body',\n",
    "'clothing',\n",
    "'clothing storage',\n",
    "'coffee',\n",
    "'elevator',\n",
    "'hair',\n",
    "'host_identity_verified',\n",
    "'host_verifications',\n",
    "'kitchen essentials',\n",
    "'allowed',\n",
    "'basics',\n",
    "'beds',\n",
    "'dryer bed',\n",
    "'hair dryer',\n",
    "'maker',\n",
    "'microwave hangers',\n",
    "'oven',\n",
    "'stove',\n",
    "'review_scores_rating',\n",
    "'review_scores_accuracy',\n",
    "'review_scores_cleanliness',\n",
    "'review_scores_checkin',\n",
    "'review_scores_communication',\n",
    "'review_scores_location',\n",
    "'review_scores_value',\n",
    "'host_is_superhost',\n",
    "'bathrooms_text',\n",
    "'precio_m2',\n",
    "'latitude',\n",
    "'longitude',\n",
    "'amenities',\n",
    "'number_of_reviews']\n",
    "\n",
    "\n",
    "x = df[variables_finales].copy()\n",
    "\n",
    "target = 'pisos_rentables'\n",
    "y = df[target].copy()\n",
    "\n",
    "\n",
    "\n",
    "nombre_pipe = 'pipe_entrenamiento.pickle'\n",
    "ruta_pipe = ruta_proyecto + '/04_Modelos/' + nombre_pipe\n",
    "with open(ruta_pipe, mode='rb') as file:\n",
    "    pipe_entrenamiento = cloudpickle.load(file)\n",
    "\n",
    "    \n",
    "\n",
    "pipe_ejecucion = pipe_entrenamiento.fit(x,y)\n",
    "nombre_pipe_ejecucion = 'pipe_ejecucion.pickle'\n",
    "ruta_pipe_ejecucion = ruta_proyecto + '/04_Modelos/' + nombre_pipe_ejecucion\n",
    "with open(ruta_pipe_ejecucion, mode='wb') as file:\n",
    "   cloudpickle.dump(pipe_ejecucion, file)\n",
    "pipe_ejecucion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc46e05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.367px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
